{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27eda919-ad0d-4b7c-a4b4-9adb4b076beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score,accuracy_score,recall_score,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d491c6f5-5fe8-42a3-bd9b-1769e10cd6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan approval dataset\n",
    "loan_df = pd.read_csv(\"loan_approval_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbce610-fde5-4f4a-8e5c-4d34676d8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unique identifier as it does not contribute to prediction\n",
    "loan_df= loan_df.drop(columns=['Applicant_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eedc3de-d5b3-4a94-88f1-371f841beac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns (float type) to handle missing values\n",
    "# separately using appropriate numerical imputation strategies\n",
    "num_mis_val = loan_df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# Identify categorical columns (object type) for separate\n",
    "# categorical missing value treatment (e.g., mode imputation)\n",
    "cat_mis_val = loan_df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9190801a-d507-41d9-8474-65e5a7ac0a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i learnt this new method of filling the missing value\n",
    "\n",
    "# Handle missing values using SimpleImputer\n",
    "# Numerical features are imputed with the mean to preserve overall distribution\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in numerical columns\n",
    "num_imp = SimpleImputer(strategy='mean')\n",
    "loan_df[num_mis_val] = num_imp.fit_transform(loan_df[num_mis_val])\n",
    "\n",
    "# Impute missing values in categorical columns\n",
    "# Most frequent value (mode) is used to retain category consistency\n",
    "cat_imp = SimpleImputer(strategy='most_frequent')\n",
    "loan_df[cat_mis_val] = cat_imp.fit_transform(loan_df[cat_mis_val])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8558fe01-4aa9-4130-9f48-1a3a76c0fcd5",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78a023c-9f64-4fce-8907-b7607322f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables into numerical form using LabelEncoder\n",
    "# This is required as machine learning models cannot work with string values\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # new thing\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode Education_Level (ordinal/binary categorical feature)\n",
    "loan_df['Education_Level'] = le.fit_transform(loan_df['Education_Level'])\n",
    "\n",
    "# Encode target variable (Loan_Approved) into binary numerical labels\n",
    "# This enables supervised learning model training\n",
    "loan_df['Loan_Approved'] = le.fit_transform(loan_df['Loan_Approved'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfeaff11-8d04-4ac9-af34-76160db0f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply One-Hot Encoding to nominal categorical features\n",
    "# OneHotEncoder is preferred here to avoid introducing\n",
    "# artificial ordinal relationships between categories\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# List of categorical columns to be one-hot encoded\n",
    "col = [\n",
    "    'Employment_Status',\n",
    "    'Marital_Status',\n",
    "    'Loan_Purpose',\n",
    "    'Property_Area',\n",
    "    'Gender',\n",
    "    'Employer_Category'\n",
    "]\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "# - drop='first' helps reduce multicollinearity (dummy variable trap)\n",
    "# - sparse_output=False returns a dense NumPy array\n",
    "# - handle_unknown='ignore' ensures robustness during inference\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse_output=False,\n",
    "    handle_unknown='ignore'\n",
    ")\n",
    "\n",
    "# Fit encoder on categorical features and transform them\n",
    "encoded = ohe.fit_transform(loan_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac47d5e1-05be-407a-b8e2-165353899722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded NumPy array into a DataFrame with meaningful column names\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded,\n",
    "    columns=ohe.get_feature_names_out(col),\n",
    "    index=loan_df.index\n",
    ")\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded features\n",
    "# to form the final preprocessed dataset\n",
    "loan_df = pd.concat(\n",
    "    [loan_df.drop(columns=col), encoded_df],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8303b33-4c9b-44d2-877b-4eb4d5b55edd",
   "metadata": {},
   "source": [
    "# Train-Test-split + Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d3b6f2-c419-416b-85d8-5eeb1ad81e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "# Loan_Approved is the label we want the model to predict\n",
    "X = loan_df.drop(columns=['Loan_Approved'],axis=1)\n",
    "y = loan_df['Loan_Approved']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# Test size of 20% ensures fair evaluation on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843a2179-c910-4bca-87a3-9bc285277e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler to normalize feature values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler ONLY on training data to learn scaling parameters\n",
    "# This prevents data leakage from the test set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same scaling transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d074e-fd2c-45d4-8446-f0afaff0b2f8",
   "metadata": {},
   "source": [
    "# Train & Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ba89e9-a0c4-466e-be36-0b7c1b322f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation For Logistic Regression\n",
      "Precision: 0.7833333333333333\n",
      "Accuracy: 0.865\n",
      "Recall: 0.7704918032786885\n",
      "F1: 0.7768595041322314\n",
      "cm: [[126  13]\n",
      " [ 14  47]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Initialize Logistic Regression classifier\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# Train the model using scaled training data\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions on scaled test data\n",
    "y_pred = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation metrics to assess model performance\n",
    "# Multiple metrics are used to avoid relying only on accuracy\n",
    "print(\"Evaluation For Logistic Regression\")\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred))\n",
    "print('cm:', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e716c-dfdc-4ac0-b5ca-5a9b37891217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
